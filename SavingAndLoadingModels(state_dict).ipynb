{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SavingAndLoadingModels(state_dict).ipynb",
      "provenance": [],
      "mount_file_id": "1K2I-rcBIo1PzQ3H21FEwqnzeDnzrHS6I",
      "authorship_tag": "ABX9TyNI0YqQtRgZdUSGeUKAdSEj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKY3mOjEyIlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti4lwSOYyd5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_data = pd.read_csv('/content/drive/My Drive/Deep_Learning_Projects/Wine_Dataset/wine.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qXzO8syygkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "0ca034f8-ea11-48fc-d306-ace17d1682ff"
      },
      "source": [
        "wine_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class  Alcohol  Malic acid  ...   Hue  OD280/OD315 of diluted wines  Proline\n",
              "0      0    14.23        1.71  ...  1.04                          3.92     1065\n",
              "1      0    13.20        1.78  ...  1.05                          3.40     1050\n",
              "2      0    13.16        2.36  ...  1.03                          3.17     1185\n",
              "3      0    14.37        1.95  ...  0.86                          3.45     1480\n",
              "4      0    13.24        2.59  ...  1.04                          2.93      735\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_aAYPIyypar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40aa8907-ed3b-4cf9-c33f-9c87c4a57406"
      },
      "source": [
        "wine_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqQjqI3Syr1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "3dc41e9f-9f20-4fc5-928f-de4d52ed63f4"
      },
      "source": [
        "wine_data.sample(8)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>14.06</td>\n",
              "      <td>1.63</td>\n",
              "      <td>2.28</td>\n",
              "      <td>16.0</td>\n",
              "      <td>126</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.10</td>\n",
              "      <td>5.65</td>\n",
              "      <td>1.09</td>\n",
              "      <td>3.71</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>2</td>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0</td>\n",
              "      <td>13.82</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.42</td>\n",
              "      <td>14.0</td>\n",
              "      <td>111</td>\n",
              "      <td>3.88</td>\n",
              "      <td>3.74</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.87</td>\n",
              "      <td>7.05</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3.26</td>\n",
              "      <td>1190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>1</td>\n",
              "      <td>11.66</td>\n",
              "      <td>1.88</td>\n",
              "      <td>1.92</td>\n",
              "      <td>16.0</td>\n",
              "      <td>97</td>\n",
              "      <td>1.61</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.15</td>\n",
              "      <td>3.80</td>\n",
              "      <td>1.23</td>\n",
              "      <td>2.14</td>\n",
              "      <td>428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0</td>\n",
              "      <td>13.05</td>\n",
              "      <td>1.73</td>\n",
              "      <td>2.04</td>\n",
              "      <td>12.4</td>\n",
              "      <td>92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.17</td>\n",
              "      <td>2.91</td>\n",
              "      <td>7.20</td>\n",
              "      <td>1.12</td>\n",
              "      <td>2.91</td>\n",
              "      <td>1150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>14.02</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.21</td>\n",
              "      <td>16.0</td>\n",
              "      <td>96</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.33</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.98</td>\n",
              "      <td>4.70</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.59</td>\n",
              "      <td>1035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0</td>\n",
              "      <td>13.90</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.12</td>\n",
              "      <td>16.0</td>\n",
              "      <td>101</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.21</td>\n",
              "      <td>2.14</td>\n",
              "      <td>6.10</td>\n",
              "      <td>0.91</td>\n",
              "      <td>3.33</td>\n",
              "      <td>985</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Class  Alcohol  Malic acid  ...   Hue  OD280/OD315 of diluted wines  Proline\n",
              "20       0    14.06        1.63  ...  1.09                          3.71      780\n",
              "177      2    14.13        4.10  ...  0.61                          1.60      560\n",
              "52       0    13.82        1.75  ...  1.01                          3.26     1190\n",
              "75       1    11.66        1.88  ...  1.23                          2.14      428\n",
              "50       0    13.05        1.73  ...  1.12                          2.91     1150\n",
              "29       0    14.02        1.68  ...  1.04                          3.59     1035\n",
              "0        0    14.23        1.71  ...  1.04                          3.92     1065\n",
              "47       0    13.90        1.68  ...  0.91                          3.33      985\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXqqi7yEytui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "0b272d8f-728a-477d-e1f3-18ec45f0ce95"
      },
      "source": [
        "wine_features = wine_data.drop('Class', axis=1)\n",
        "wine_features.sample(8)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>14.38</td>\n",
              "      <td>3.59</td>\n",
              "      <td>2.28</td>\n",
              "      <td>16.0</td>\n",
              "      <td>102</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.27</td>\n",
              "      <td>2.19</td>\n",
              "      <td>4.90</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.44</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>11.96</td>\n",
              "      <td>1.09</td>\n",
              "      <td>2.30</td>\n",
              "      <td>21.0</td>\n",
              "      <td>101</td>\n",
              "      <td>3.38</td>\n",
              "      <td>2.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>1.65</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.99</td>\n",
              "      <td>3.13</td>\n",
              "      <td>886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>12.25</td>\n",
              "      <td>4.72</td>\n",
              "      <td>2.54</td>\n",
              "      <td>21.0</td>\n",
              "      <td>89</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.80</td>\n",
              "      <td>3.85</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.27</td>\n",
              "      <td>720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>11.62</td>\n",
              "      <td>1.99</td>\n",
              "      <td>2.28</td>\n",
              "      <td>18.0</td>\n",
              "      <td>98</td>\n",
              "      <td>3.02</td>\n",
              "      <td>2.26</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.35</td>\n",
              "      <td>3.25</td>\n",
              "      <td>1.16</td>\n",
              "      <td>2.96</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>13.72</td>\n",
              "      <td>1.43</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.7</td>\n",
              "      <td>108</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0.19</td>\n",
              "      <td>2.04</td>\n",
              "      <td>6.80</td>\n",
              "      <td>0.89</td>\n",
              "      <td>2.87</td>\n",
              "      <td>1285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>12.37</td>\n",
              "      <td>1.21</td>\n",
              "      <td>2.56</td>\n",
              "      <td>18.1</td>\n",
              "      <td>98</td>\n",
              "      <td>2.42</td>\n",
              "      <td>2.65</td>\n",
              "      <td>0.37</td>\n",
              "      <td>2.08</td>\n",
              "      <td>4.60</td>\n",
              "      <td>1.19</td>\n",
              "      <td>2.30</td>\n",
              "      <td>678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>12.72</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.28</td>\n",
              "      <td>22.5</td>\n",
              "      <td>84</td>\n",
              "      <td>1.38</td>\n",
              "      <td>1.76</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.63</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.88</td>\n",
              "      <td>2.42</td>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Alcohol  Malic acid   Ash  ...   Hue  OD280/OD315 of diluted wines  Proline\n",
              "46     14.38        3.59  2.28  ...  1.04                          3.44     1065\n",
              "74     11.96        1.09  2.30  ...  0.99                          3.13      886\n",
              "136    12.25        4.72  2.54  ...  0.75                          1.27      720\n",
              "94     11.62        1.99  2.28  ...  1.16                          2.96      345\n",
              "174    13.40        3.91  2.48  ...  0.70                          1.56      750\n",
              "58     13.72        1.43  2.50  ...  0.89                          2.87     1285\n",
              "65     12.37        1.21  2.56  ...  1.19                          2.30      678\n",
              "107    12.72        1.75  2.28  ...  0.88                          2.42      488\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr5UuveOywc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "32d38ce2-4f89-427c-d6f0-7cd8ffafc1e3"
      },
      "source": [
        "wine_target = wine_data[['Class']]\n",
        "wine_target.sample(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Class\n",
              "15       0\n",
              "120      1\n",
              "149      2\n",
              "107      1\n",
              "72       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwIWBg55yyUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(wine_features, wine_target, test_size=0.4, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYE3QQyey0gQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb28268e-833f-4641-c878-4fa405f8a9ef"
      },
      "source": [
        "X_train.shape, Y_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((106, 13), (106, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNn1mbQ8y2sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = torch.from_numpy(X_train.values).float()\n",
        "X_test = torch.from_numpy(X_test.values).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT5uMiYPy4Qd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b78026e-89a9-453b-b27d-cb604781453b"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([106, 13]), torch.Size([72, 13]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBpexgIWy572",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = torch.from_numpy(Y_train.values).view(1,-1)[0]\n",
        "Y_test = torch.from_numpy(Y_test.values).view(1,-1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rQWS_bj0Bsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "201143d8-6354-4246-fdfc-624374e3d34f"
      },
      "source": [
        "Y_train.shape, Y_test.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([106]), torch.Size([72]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qFzUNKL0C_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 13\n",
        "output_size = 3\n",
        "hidden_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LrmSnMk0Ewx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = torch.sigmoid(self.fc1(X))\n",
        "    X = torch.sigmoid(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return F.log_softmax(X, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyKCm9v20GcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lClmOSDp0IFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSHShLE60JhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH-tMyIY0K-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7d3d0709-59a3-40ea-ab31-6cdc0cc29328"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  Y_pred = model(X_train)\n",
        "\n",
        "  loss = loss_fn(Y_pred, Y_train)\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100 == 0:\n",
        "    print('Epoch : ', epoch, ' Loss : ', loss.item())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :  0  Loss :  1.1083730459213257\n",
            "Epoch :  100  Loss :  0.2725227475166321\n",
            "Epoch :  200  Loss :  0.1992054581642151\n",
            "Epoch :  300  Loss :  0.0427107997238636\n",
            "Epoch :  400  Loss :  0.03635503351688385\n",
            "Epoch :  500  Loss :  0.03384397551417351\n",
            "Epoch :  600  Loss :  0.03217708319425583\n",
            "Epoch :  700  Loss :  0.03089394047856331\n",
            "Epoch :  800  Loss :  0.029771754518151283\n",
            "Epoch :  900  Loss :  0.028471240773797035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FNcOmFY0MSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d07cb2d3-eb71-4b3e-d330-088435e258c8"
      },
      "source": [
        "model.state_dict"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.state_dict of Net(\n",
              "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZin70A40Ws-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ee5c65f-a7f1-487f-dfaa-6234f284f639"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('fc1.weight',\n",
              "              tensor([[ 0.0820,  0.0365,  0.1825,  ..., -0.1929, -0.0132,  0.2207],\n",
              "                      [-0.1826, -0.1811,  0.2170,  ..., -0.1283,  0.1835,  0.1049],\n",
              "                      [ 0.2356,  0.1473, -0.1996,  ..., -0.1075, -0.1872, -0.2618],\n",
              "                      ...,\n",
              "                      [ 0.1229, -0.2130,  0.1868,  ..., -0.0745, -0.0675, -0.2241],\n",
              "                      [-0.0425,  0.0500,  0.1303,  ..., -0.0845, -0.1100,  0.2615],\n",
              "                      [ 0.1823, -0.2399,  0.0433,  ...,  0.2523, -0.2106,  0.1548]])),\n",
              "             ('fc1.bias',\n",
              "              tensor([-0.0901, -0.0834, -0.0110, -0.2185,  0.1710, -0.0484, -0.2192,  0.1567,\n",
              "                       0.0515, -0.0661, -0.0487, -0.0583,  0.1573, -0.0810,  0.0103,  0.0367,\n",
              "                       0.2283,  0.1092, -0.1011,  0.1463, -0.2664, -0.1358,  0.0099, -0.2386,\n",
              "                       0.2043,  0.0947, -0.2019,  0.0272,  0.0391, -0.0369, -0.1018,  0.0589,\n",
              "                       0.1874,  0.0429,  0.0246,  0.1709,  0.1665,  0.0210, -0.2480,  0.2665,\n",
              "                      -0.1037, -0.1891,  0.0364, -0.0710, -0.0974,  0.2093,  0.0031,  0.2285,\n",
              "                      -0.1329, -0.2274,  0.2135,  0.0034,  0.2340, -0.0473, -0.2667,  0.2298,\n",
              "                      -0.0793,  0.2177, -0.1247,  0.2234, -0.0747, -0.0524, -0.0236, -0.2050,\n",
              "                       0.2769,  0.2429, -0.1215, -0.1406, -0.1742,  0.1141,  0.4059,  0.1596,\n",
              "                      -0.0109, -0.1634, -0.2089, -0.5825, -0.0269,  0.2301, -0.1519, -0.0112,\n",
              "                       0.2747,  0.0937, -0.0427, -0.1305,  0.0856, -0.2120,  0.2439, -0.0164,\n",
              "                       1.3976, -0.0532,  0.0929, -0.0777,  0.2424,  0.9999, -0.2602, -0.0243,\n",
              "                       0.0455,  0.0800, -0.0221, -0.1305])),\n",
              "             ('fc2.weight',\n",
              "              tensor([[ 0.0726,  0.0156, -0.0259,  ..., -0.0826,  0.0715,  0.0026],\n",
              "                      [ 0.0573,  0.0894,  0.0807,  ...,  0.0180,  0.0856,  0.0766],\n",
              "                      [ 0.0417, -0.0207, -0.0330,  ...,  0.0788, -0.0515, -0.0320],\n",
              "                      ...,\n",
              "                      [-0.0380,  0.0253, -0.0337,  ...,  0.0861,  0.0365,  0.0345],\n",
              "                      [-0.0440,  0.0183, -0.0729,  ...,  0.0509, -0.0172, -0.0529],\n",
              "                      [ 0.0627, -0.0690, -0.0829,  ...,  0.0957,  0.0527,  0.0890]])),\n",
              "             ('fc2.bias',\n",
              "              tensor([ 0.1224,  0.1004,  0.1027, -0.0335,  0.0032,  0.0332, -0.0983, -0.0233,\n",
              "                       0.0404,  0.0327, -0.0310, -0.0134,  0.0914, -0.0562, -0.0396, -0.0809,\n",
              "                      -0.1009,  0.0856, -0.0262,  0.0564,  0.0080, -0.0111, -0.0587, -0.0720,\n",
              "                      -0.0806, -0.0740, -0.0016, -0.0369, -0.1524, -0.0314, -0.0754, -0.0787,\n",
              "                      -0.0179,  0.0096,  0.0798, -0.0169, -0.0527,  0.0362, -0.0229, -0.0658,\n",
              "                      -0.0185,  0.0245,  0.0524, -0.0632, -0.0743,  0.0063,  0.0120, -0.0228,\n",
              "                      -0.0084, -0.0759,  0.0665, -0.0784, -0.0436, -0.0495,  0.0851, -0.0990,\n",
              "                       0.0465,  0.0626, -0.0005,  0.0452, -0.1409,  0.0305, -0.0003,  0.0042,\n",
              "                       0.0945,  0.0113, -0.0236, -0.0836, -0.1184,  0.0410, -0.0097,  0.0588,\n",
              "                      -0.0837,  0.0757, -0.0929,  0.0602,  0.1045,  0.0733,  0.0724, -0.1032,\n",
              "                      -0.0560, -0.0185,  0.0429,  0.0091,  0.0714, -0.1215, -0.0921,  0.0033,\n",
              "                      -0.0596, -0.0214, -0.0320,  0.0528, -0.0109, -0.0659,  0.0162,  0.0571,\n",
              "                      -0.0505, -0.0095, -0.0558, -0.0672])),\n",
              "             ('fc3.weight',\n",
              "              tensor([[ 2.3687e-01,  5.9010e-01,  2.4395e-01, -6.6457e-01, -3.2644e-01,\n",
              "                       -5.9763e-01, -4.7221e-01, -3.2839e-01,  1.2523e-02, -3.2916e-01,\n",
              "                        4.6735e-01, -3.3980e-01,  5.6867e-01, -4.5759e-02, -3.8713e-01,\n",
              "                        4.5142e-01,  4.8079e-01,  4.5511e-01, -3.3384e-01, -4.7557e-01,\n",
              "                        5.5069e-01, -7.2283e-02, -1.1977e-02,  3.2955e-01,  2.3285e-01,\n",
              "                       -5.7216e-01,  1.4610e-01,  1.6253e-01,  2.8909e-02, -5.1222e-01,\n",
              "                       -3.5572e-01,  5.0226e-01, -7.5325e-01, -5.4730e-01, -3.7804e-01,\n",
              "                       -6.7561e-01, -1.2464e-01,  4.1142e-01, -6.2970e-01,  2.9820e-01,\n",
              "                        5.3710e-01,  4.0726e-01,  4.4278e-01, -6.1103e-01, -4.5101e-01,\n",
              "                        5.3837e-01, -3.4706e-01, -5.9620e-01,  3.7610e-01, -6.2740e-02,\n",
              "                        3.0902e-01,  5.4559e-01, -4.1254e-01, -3.5968e-01, -5.5796e-01,\n",
              "                       -3.3194e-01,  4.8653e-01, -4.5466e-01, -3.8610e-01,  5.0261e-01,\n",
              "                       -5.7467e-02, -4.9561e-01, -4.5278e-01, -5.8422e-01,  5.1841e-01,\n",
              "                        3.1398e-01,  2.8914e-01, -4.1656e-01, -5.2524e-01,  3.0589e-01,\n",
              "                        2.9899e-01,  2.8998e-01,  5.9758e-01,  5.0725e-01,  4.3816e-01,\n",
              "                        2.0921e-01,  2.8824e-01, -5.3139e-01, -7.2596e-01, -2.9630e-01,\n",
              "                        6.5043e-02, -6.1487e-01,  5.0958e-01, -3.7816e-01,  1.4430e-01,\n",
              "                       -2.4549e-01,  4.1625e-01,  3.3695e-01,  6.4960e-01,  3.6825e-01,\n",
              "                       -5.1704e-01,  5.4094e-01,  1.1982e-01, -6.0579e-01,  4.5700e-01,\n",
              "                       -3.7575e-01, -4.0690e-01,  3.8533e-01, -5.0808e-01, -6.6116e-01],\n",
              "                      [-4.3010e-01, -3.7050e-01,  2.1646e-01,  1.4529e-01, -3.2054e-01,\n",
              "                        9.0706e-02,  2.9472e-01, -2.4358e-01, -4.7648e-01,  3.7471e-02,\n",
              "                       -2.7476e-01,  3.4566e-01, -1.0690e-01,  3.8284e-01,  4.0209e-01,\n",
              "                        6.4944e-02, -1.0461e-01, -2.5199e-01,  2.1282e-01,  9.1524e-02,\n",
              "                        2.4202e-02, -1.6620e-01, -2.6607e-01,  1.4599e-01,  1.9530e-01,\n",
              "                        6.6179e-02,  2.5585e-01,  4.2939e-01, -6.5114e-04,  1.0726e-01,\n",
              "                       -3.0626e-01, -3.0236e-01,  3.6672e-01,  2.5482e-01,  1.4088e-01,\n",
              "                        1.3574e-01,  3.9980e-01,  1.1196e-01, -2.0543e-01,  1.1938e-01,\n",
              "                       -4.5229e-01, -1.9979e-02, -2.8949e-02,  1.1344e-01,  1.6494e-01,\n",
              "                       -1.2960e-01, -2.4023e-01,  1.5389e-01,  1.5940e-01, -6.7150e-02,\n",
              "                       -7.1412e-02,  1.0705e-02, -3.5080e-01,  3.8489e-01,  9.4073e-02,\n",
              "                        3.0006e-01, -1.9136e-01,  6.8311e-02, -3.9175e-01,  1.7780e-02,\n",
              "                       -1.0995e-01,  3.9565e-02,  2.6805e-01, -3.6760e-01,  2.9769e-02,\n",
              "                        1.6432e-01,  1.9338e-01, -1.3626e-01,  3.4914e-01,  4.5322e-02,\n",
              "                        6.4242e-02,  3.5858e-01, -1.2412e-01, -2.5278e-01,  2.6979e-02,\n",
              "                        1.2355e-01, -4.4314e-01,  1.0969e-01,  1.7553e-01, -2.3173e-01,\n",
              "                       -4.7144e-01,  1.6732e-01, -2.4848e-01,  3.0241e-01, -3.9098e-01,\n",
              "                        4.0005e-01,  1.8907e-01,  1.1600e-01, -6.1639e-02,  2.2438e-01,\n",
              "                        3.1201e-02, -1.4883e-02,  2.0192e-01,  5.0471e-02,  6.1073e-02,\n",
              "                       -7.2586e-02,  2.8189e-01,  1.0746e-01,  3.5008e-01, -9.1182e-02],\n",
              "                      [ 3.5890e-01, -1.9043e-01, -6.3594e-01,  5.0538e-01,  6.4930e-01,\n",
              "                        3.2349e-01,  2.0164e-01,  4.9204e-01,  5.9066e-01,  4.2111e-01,\n",
              "                       -1.8747e-01, -1.2459e-01, -4.7189e-01, -4.2593e-01, -2.2421e-01,\n",
              "                       -7.5546e-01, -6.3817e-01, -1.2734e-01,  1.3064e-01,  3.8300e-01,\n",
              "                       -6.1414e-01,  5.8305e-01,  4.8913e-01, -5.7968e-01, -4.6467e-01,\n",
              "                        4.4339e-01, -7.2924e-01, -7.2985e-01,  1.9009e-02,  4.6472e-01,\n",
              "                        6.7908e-01, -2.5749e-01,  3.3802e-01,  1.8070e-01,  3.1568e-01,\n",
              "                        4.2167e-01, -2.7989e-01, -6.0878e-01,  6.3826e-01, -6.4920e-01,\n",
              "                       -5.5925e-02, -4.8519e-01, -4.4131e-01,  3.3923e-01,  6.5964e-02,\n",
              "                       -6.6270e-01,  5.5501e-01,  3.9734e-01, -6.1815e-01, -2.2348e-02,\n",
              "                       -5.2758e-01, -6.2209e-01,  7.1040e-01, -1.3536e-01,  3.2113e-01,\n",
              "                       -2.2219e-01, -3.0005e-01,  4.5490e-01,  7.0500e-01, -6.1294e-01,\n",
              "                       -5.8834e-02,  5.3142e-01,  1.2769e-01,  6.5955e-01, -6.4899e-01,\n",
              "                       -4.5929e-01, -4.2334e-01,  4.7440e-01,  2.2416e-02, -5.3136e-01,\n",
              "                       -5.1000e-01, -6.8749e-01, -6.5274e-01, -3.7922e-01, -5.9078e-01,\n",
              "                       -4.9693e-01,  2.2355e-01,  4.1304e-01,  3.0264e-01,  5.7071e-01,\n",
              "                        5.1148e-01,  3.7718e-01, -4.7034e-01,  1.2081e-01,  2.8505e-01,\n",
              "                       -2.9688e-01, -7.6428e-01, -5.8482e-01, -5.9112e-01, -5.7806e-01,\n",
              "                        5.8985e-01, -6.3591e-01, -5.5217e-01,  5.7570e-01, -6.9665e-01,\n",
              "                        5.5132e-01,  2.7938e-01, -7.0476e-01,  7.1468e-02,  5.6221e-01]])),\n",
              "             ('fc3.bias', tensor([ 0.0376, -0.0660,  0.0117]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU3vAbXk0a5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "e1d7f171-706f-41da-d5df-f6060a12296c"
      },
      "source": [
        "optimizer.state_dict"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Optimizer.state_dict of Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.01\n",
              "    weight_decay: 0\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIZT8iKG0krW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36a526d6-f91e-4373-cfde-e027af7a4b5c"
      },
      "source": [
        "optimizer.state_dict()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'param_groups': [{'amsgrad': False,\n",
              "   'betas': (0.9, 0.999),\n",
              "   'eps': 1e-08,\n",
              "   'lr': 0.01,\n",
              "   'params': [139804118556464,\n",
              "    139804118556176,\n",
              "    139804311322840,\n",
              "    139804311322768,\n",
              "    139804311325504,\n",
              "    139804311324136],\n",
              "   'weight_decay': 0}],\n",
              " 'state': {139804118556176: {'exp_avg': tensor([ 0.0000e+00, -5.6052e-45,  5.6052e-45, -1.3200e-18, -5.6052e-45,\n",
              "            2.4416e-26,  0.0000e+00, -4.2599e-43, -7.9152e-41, -6.6642e-35,\n",
              "            2.5960e-22, -5.6052e-45,  0.0000e+00,  1.0359e-18,  0.0000e+00,\n",
              "           -5.6052e-45, -6.4482e-15,  0.0000e+00, -5.9419e-28, -6.7323e-19,\n",
              "           -2.1108e-21, -1.1701e-27,  0.0000e+00,  9.8022e-21, -5.6052e-45,\n",
              "           -8.6040e-43,  1.3135e-25,  0.0000e+00, -4.8111e-34,  0.0000e+00,\n",
              "            6.6499e-21, -5.6052e-45,  0.0000e+00,  0.0000e+00,  5.7662e-36,\n",
              "            0.0000e+00, -2.8950e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.6173e-04,\n",
              "            0.0000e+00,  0.0000e+00, -1.3477e-39, -1.2284e-35,  2.4432e-29,\n",
              "            0.0000e+00,  3.8745e-28,  0.0000e+00,  0.0000e+00,  2.5432e-23,\n",
              "            4.5861e-28,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "           -5.6052e-45,  0.0000e+00,  0.0000e+00,  8.9755e-19,  8.0709e-29,\n",
              "            0.0000e+00,  2.1869e-17,  1.6873e-31,  7.9441e-27,  0.0000e+00,\n",
              "           -2.9866e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5343e-39,\n",
              "            8.3673e-05,  0.0000e+00, -5.6052e-45,  6.1460e-21,  0.0000e+00,\n",
              "           -5.6052e-45,  6.6479e-15, -9.9469e-36,  0.0000e+00, -7.3265e-26,\n",
              "            0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2677e-04,  2.0972e-32,\n",
              "            0.0000e+00,  0.0000e+00,  0.0000e+00, -7.8243e-05,  0.0000e+00,\n",
              "           -5.6052e-45, -7.4459e-36,  4.6510e-35,  0.0000e+00,  0.0000e+00]),\n",
              "   'exp_avg_sq': tensor([0.0000e+00, 4.3092e-18, 0.0000e+00, 7.9887e-32, 6.3080e-25, 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2612e-08, 2.0832e-13, 6.0507e-12,\n",
              "           0.0000e+00, 7.3421e-13, 0.0000e+00, 2.1770e-26, 1.0818e-12, 0.0000e+00,\n",
              "           0.0000e+00, 3.8463e-32, 4.4590e-13, 0.0000e+00, 0.0000e+00, 3.2519e-34,\n",
              "           6.1843e-16, 0.0000e+00, 3.5032e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "           2.9401e-36, 3.1091e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "           9.4827e-14, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00, 1.4705e-04, 0.0000e+00, 0.0000e+00, 1.8554e-07,\n",
              "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "           1.8944e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "           2.0015e-13, 0.0000e+00, 0.0000e+00, 2.9939e-10, 0.0000e+00, 0.0000e+00,\n",
              "           5.7923e-29, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1789e-07, 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9012e-06, 0.0000e+00, 3.8338e-10,\n",
              "           1.0798e-23, 0.0000e+00, 2.6270e-10, 4.6361e-13, 0.0000e+00, 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3823e-07, 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5738e-06, 0.0000e+00, 1.9032e-20,\n",
              "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
              "   'step': 1000},\n",
              "  139804118556464: {'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "             0.0000e+00,  0.0000e+00],\n",
              "           [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
              "            -5.6052e-45, -5.6052e-45],\n",
              "           [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
              "             5.6052e-45,  5.6052e-45],\n",
              "           ...,\n",
              "           [ 5.7755e-34,  1.1743e-34,  1.0563e-34,  ...,  4.0387e-35,\n",
              "             1.5278e-34,  1.4690e-32],\n",
              "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "             0.0000e+00,  0.0000e+00],\n",
              "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "             0.0000e+00,  0.0000e+00]]),\n",
              "   'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "            0.0000e+00],\n",
              "           [6.5516e-16, 1.7833e-17, 2.2851e-17,  ..., 5.1358e-18, 3.7176e-17,\n",
              "            5.0446e-13],\n",
              "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "            0.0000e+00],\n",
              "           ...,\n",
              "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "            0.0000e+00],\n",
              "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "            0.0000e+00],\n",
              "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "            0.0000e+00]]),\n",
              "   'step': 1000},\n",
              "  139804311322768: {'exp_avg': tensor([-6.3089e-06, -1.2520e-06,  1.2492e-06,  2.6116e-06, -1.2088e-06,\n",
              "            2.1415e-06,  1.4657e-06, -9.7196e-07, -2.3620e-07,  3.9153e-07,\n",
              "           -1.2027e-06, -3.7168e-06, -1.9209e-06, -9.1286e-08, -5.0590e-06,\n",
              "            1.1705e-06, -1.0750e-06, -8.5079e-07,  8.6866e-07,  1.7125e-06,\n",
              "           -6.4740e-08, -8.0235e-08, -5.9617e-07,  1.1277e-06,  8.2299e-07,\n",
              "            1.9160e-06,  1.3438e-06,  2.2028e-06,  2.0788e-10,  1.8589e-06,\n",
              "           -1.4158e-06, -1.5405e-06,  2.6572e-06,  1.5552e-06,  1.6662e-06,\n",
              "            2.6732e-06, -1.6315e-06,  9.0351e-07, -1.5770e-06,  1.1950e-06,\n",
              "           -1.6751e-07, -1.0777e-07, -6.3773e-07,  2.1581e-06,  7.8791e-07,\n",
              "           -1.6325e-06, -7.7580e-07,  2.3811e-06,  1.1707e-06, -2.0467e-07,\n",
              "           -3.4474e-08, -1.3369e-07, -1.3893e-06, -3.6927e-06,  2.0783e-06,\n",
              "           -4.3942e-06, -1.6921e-06,  1.3256e-06, -1.1937e-06,  4.3444e-07,\n",
              "           -1.6709e-09,  1.0496e-06,  9.4022e-07, -1.2708e-06,  4.0026e-07,\n",
              "            8.7191e-07,  7.0159e-07, -1.3824e-06, -1.0885e-06,  1.0362e-06,\n",
              "            6.7658e-07,  1.9017e-06, -1.8783e-06, -1.9298e-06,  5.5997e-07,\n",
              "            8.7867e-07, -4.7037e-06,  1.9493e-06,  2.5113e-06, -8.3288e-07,\n",
              "            1.0238e-06,  2.4554e-06, -2.1241e-06,  3.2641e-07,  2.3960e-06,\n",
              "           -3.6505e-06,  1.4594e-06,  9.9614e-07, -1.5916e-06,  1.0722e-06,\n",
              "            5.8523e-07, -3.9467e-07,  9.0193e-07,  1.6326e-06,  8.9871e-07,\n",
              "           -9.1757e-07,  1.5919e-06,  1.0974e-06, -2.5625e-07,  1.3280e-07]),\n",
              "   'exp_avg_sq': tensor([4.0035e-07, 5.2492e-07, 6.1570e-07, 9.0461e-07, 4.1878e-07, 4.2929e-07,\n",
              "           3.6422e-07, 4.2647e-07, 4.1771e-07, 3.4934e-07, 1.5312e-07, 3.3285e-07,\n",
              "           6.1232e-07, 4.0457e-07, 3.6647e-07, 1.1111e-06, 9.0843e-07, 2.8798e-07,\n",
              "           2.3068e-07, 4.8943e-07, 9.5365e-07, 5.3761e-10, 2.0111e-07, 5.2358e-07,\n",
              "           3.9091e-07, 6.6615e-07, 2.5050e-07, 8.2085e-07, 1.7539e-10, 7.3746e-07,\n",
              "           8.0885e-07, 3.4746e-07, 9.0368e-07, 2.7699e-07, 2.2571e-07, 7.5115e-07,\n",
              "           1.8329e-07, 7.4454e-07, 1.0570e-06, 6.4816e-07, 2.5856e-07, 3.6749e-07,\n",
              "           3.6000e-07, 4.6000e-07, 1.5728e-07, 1.0726e-06, 4.8784e-07, 6.7504e-07,\n",
              "           7.8765e-07, 1.9982e-09, 3.6741e-07, 9.9307e-07, 1.1727e-06, 4.0149e-07,\n",
              "           4.9307e-07, 2.1515e-07, 3.3689e-07, 5.9101e-07, 6.2483e-07, 7.6355e-07,\n",
              "           1.5369e-10, 8.0597e-07, 1.7132e-07, 1.1739e-06, 9.1012e-07, 4.6932e-07,\n",
              "           3.6742e-07, 4.7590e-07, 4.2826e-07, 4.0074e-07, 4.3476e-07, 8.2316e-07,\n",
              "           1.0710e-06, 4.9524e-07, 7.0213e-07, 4.1090e-07, 2.2081e-07, 5.1404e-07,\n",
              "           6.3259e-07, 7.2247e-07, 5.4317e-07, 7.1957e-07, 5.2660e-07, 2.5593e-07,\n",
              "           1.2923e-07, 2.6199e-07, 1.1334e-06, 5.9042e-07, 1.0013e-06, 7.8074e-07,\n",
              "           8.2253e-07, 9.9769e-07, 4.1059e-07, 9.2930e-07, 9.6547e-07, 5.5424e-07,\n",
              "           2.1843e-07, 1.0051e-06, 4.1677e-07, 1.0047e-06]),\n",
              "   'step': 1000},\n",
              "  139804311322840: {'exp_avg': tensor([[-6.3089e-06, -6.3089e-06,  5.6052e-45,  ...,  2.7621e-34,\n",
              "            -6.3089e-06, -6.3089e-06],\n",
              "           [-1.2520e-06, -1.2520e-06,  5.6052e-45,  ...,  4.7678e-35,\n",
              "            -1.2522e-06, -1.2522e-06],\n",
              "           [ 1.2492e-06,  1.2492e-06, -5.6052e-45,  ..., -2.4356e-34,\n",
              "             1.2492e-06,  1.2492e-06],\n",
              "           ...,\n",
              "           [ 1.0974e-06,  1.0974e-06, -5.6052e-45,  ..., -2.6363e-34,\n",
              "             1.0975e-06,  1.0975e-06],\n",
              "           [-2.5625e-07, -2.5625e-07, -5.6052e-45,  ..., -5.8678e-35,\n",
              "            -2.5633e-07, -2.5633e-07],\n",
              "           [ 1.3280e-07,  1.3280e-07,  5.6052e-45,  ...,  2.1400e-34,\n",
              "             1.3284e-07,  1.3284e-07]]),\n",
              "   'exp_avg_sq': tensor([[4.0035e-07, 4.0036e-07, 0.0000e+00,  ..., 0.0000e+00, 4.0035e-07,\n",
              "            4.0035e-07],\n",
              "           [5.2492e-07, 5.2493e-07, 0.0000e+00,  ..., 0.0000e+00, 5.2492e-07,\n",
              "            5.2492e-07],\n",
              "           [6.1570e-07, 6.1570e-07, 0.0000e+00,  ..., 0.0000e+00, 6.1570e-07,\n",
              "            6.1570e-07],\n",
              "           ...,\n",
              "           [1.0051e-06, 1.0051e-06, 0.0000e+00,  ..., 0.0000e+00, 1.0051e-06,\n",
              "            1.0051e-06],\n",
              "           [4.1677e-07, 4.1677e-07, 0.0000e+00,  ..., 0.0000e+00, 4.1677e-07,\n",
              "            4.1677e-07],\n",
              "           [1.0047e-06, 1.0047e-06, 0.0000e+00,  ..., 0.0000e+00, 1.0047e-06,\n",
              "            1.0047e-06]]),\n",
              "   'step': 1000},\n",
              "  139804311324136: {'exp_avg': tensor([-1.4261e-05,  2.3149e-05, -8.8876e-06]),\n",
              "   'exp_avg_sq': tensor([6.7378e-05, 1.3053e-04, 6.9183e-05]),\n",
              "   'step': 1000},\n",
              "  139804311325504: {'exp_avg': tensor([[-3.0762e-06, -9.7635e-05, -5.6946e-05,  1.0542e-04,  2.9121e-05,\n",
              "             1.1267e-04,  9.0875e-05,  3.6943e-05,  6.8003e-06,  8.8382e-05,\n",
              "            -1.2598e-04,  2.4399e-05, -1.1484e-04, -2.0361e-05,  1.2572e-05,\n",
              "            -8.1188e-05, -1.1101e-04, -9.4392e-05,  6.7793e-05,  9.8009e-05,\n",
              "            -9.7707e-05, -2.9468e-06,  1.2938e-05, -6.1651e-05, -5.7973e-05,\n",
              "             9.5983e-05, -3.3232e-05, -3.4543e-05,  3.7790e-08,  9.4707e-05,\n",
              "             3.4831e-05, -1.1248e-04,  1.0508e-04,  1.1874e-04,  1.0393e-04,\n",
              "             1.0585e-04, -3.4301e-07, -7.1449e-05,  6.5566e-05, -6.6205e-05,\n",
              "            -9.5671e-05, -1.0055e-04, -1.0461e-04,  1.1611e-04,  9.9630e-05,\n",
              "            -1.1293e-04,  4.3805e-05,  1.0421e-04, -7.3005e-05,  1.5173e-06,\n",
              "            -9.5036e-05, -1.0408e-04,  4.0070e-05,  1.9298e-05,  1.0190e-04,\n",
              "             1.5388e-05, -1.0912e-04,  9.0720e-05,  3.1609e-05, -1.0603e-04,\n",
              "             6.2217e-08,  9.4253e-05,  1.0981e-04,  4.0893e-05, -9.5036e-05,\n",
              "            -6.9872e-05, -6.1263e-05,  7.3480e-05,  6.4677e-05, -8.1208e-05,\n",
              "            -7.7701e-05, -4.5208e-05, -1.0935e-04, -1.1576e-04, -9.2897e-05,\n",
              "            -6.3947e-05, -1.5617e-05,  1.0411e-04,  1.1139e-04,  4.2422e-05,\n",
              "             8.5782e-06,  1.0415e-04, -1.2082e-04,  7.4859e-05, -1.7110e-05,\n",
              "             5.3240e-06, -6.4511e-05, -7.0737e-05, -1.1342e-04, -6.5868e-05,\n",
              "             9.1114e-05, -9.6239e-05, -4.6663e-05,  1.0328e-04, -8.2283e-05,\n",
              "             6.2422e-05,  1.1337e-04, -7.5231e-05,  7.3179e-05,  8.7034e-05],\n",
              "           [ 2.2136e-05,  6.5732e-05, -2.2617e-05, -5.1471e-05,  8.2933e-05,\n",
              "            -6.3357e-05, -5.2017e-05,  6.2165e-05,  5.3479e-05, -2.9594e-05,\n",
              "             9.0279e-05, -8.2191e-06,  7.0454e-05, -1.2821e-05, -7.6645e-06,\n",
              "             1.2776e-05,  6.5974e-05,  6.2583e-05, -3.1688e-05, -4.5202e-05,\n",
              "             3.9489e-05,  2.2048e-04,  5.8340e-05, -2.3899e-05, -1.5154e-05,\n",
              "            -4.1387e-05, -8.5747e-05, -7.0044e-05,  8.5401e-09, -4.4209e-05,\n",
              "             6.6380e-05,  7.7259e-05, -6.0963e-05, -7.7777e-05, -5.8393e-05,\n",
              "            -5.5008e-05, -1.9828e-05, -2.9367e-06,  2.1557e-05, -1.3617e-05,\n",
              "             6.9426e-05,  4.2393e-05,  5.1919e-05, -6.4922e-05, -5.8185e-05,\n",
              "             6.7962e-05,  3.8673e-05, -5.4169e-05,  2.1016e-06,  3.5557e-06,\n",
              "             3.9229e-05,  4.8659e-05,  4.9650e-05, -9.7991e-06, -5.1875e-05,\n",
              "            -5.9861e-06,  6.8590e-05, -3.6941e-05,  6.8595e-05,  4.8053e-05,\n",
              "             3.4574e-08, -4.0633e-05, -7.1476e-05,  5.1585e-05,  3.4497e-05,\n",
              "             2.2891e-06, -1.0658e-05,  7.8130e-06, -3.3511e-05,  6.4779e-06,\n",
              "             1.5814e-05, -5.2785e-05,  6.3642e-05,  7.4668e-05,  3.0104e-05,\n",
              "            -1.1631e-05,  2.8331e-05, -4.9502e-05, -6.2210e-05,  3.8113e-05,\n",
              "             2.7924e-05, -5.4060e-05,  8.1726e-05, -4.0643e-05,  4.0694e-05,\n",
              "            -1.4250e-05, -1.6780e-05, -9.9900e-07,  6.5258e-05, -5.8231e-06,\n",
              "            -2.5614e-05,  4.1284e-05, -3.1198e-05, -4.7355e-05,  1.4978e-05,\n",
              "             2.2752e-05, -6.9489e-05,  8.8963e-06, -4.2669e-05, -2.5732e-05],\n",
              "           [-1.9059e-05,  3.1903e-05,  7.9565e-05, -5.3944e-05, -1.1205e-04,\n",
              "            -4.9315e-05, -3.8857e-05, -9.9108e-05, -6.0279e-05, -5.8787e-05,\n",
              "             3.5702e-05, -1.6179e-05,  4.4388e-05,  3.3184e-05, -4.9065e-06,\n",
              "             6.8413e-05,  4.5034e-05,  3.1810e-05, -3.6105e-05, -5.2807e-05,\n",
              "             5.8219e-05, -2.1753e-04, -7.1277e-05,  8.5552e-05,  7.3129e-05,\n",
              "            -5.4595e-05,  1.1898e-04,  1.0459e-04, -4.6329e-08, -5.0497e-05,\n",
              "            -1.0121e-04,  3.5218e-05, -4.4117e-05, -4.0958e-05, -4.5537e-05,\n",
              "            -5.0839e-05,  2.0172e-05,  7.4387e-05, -8.7123e-05,  7.9823e-05,\n",
              "             2.6246e-05,  5.8155e-05,  5.2697e-05, -5.1190e-05, -4.1444e-05,\n",
              "             4.4974e-05, -8.2477e-05, -5.0040e-05,  7.0904e-05, -5.0730e-06,\n",
              "             5.5808e-05,  5.5423e-05, -8.9720e-05, -9.4981e-06, -5.0025e-05,\n",
              "            -9.4002e-06,  4.0529e-05, -5.3778e-05, -1.0020e-04,  5.7982e-05,\n",
              "            -9.6790e-08, -5.3619e-05, -3.8338e-05, -9.2478e-05,  6.0540e-05,\n",
              "             6.7584e-05,  7.1922e-05, -8.1292e-05, -3.1165e-05,  7.4731e-05,\n",
              "             6.1889e-05,  9.7994e-05,  4.5711e-05,  4.1090e-05,  6.2793e-05,\n",
              "             7.5578e-05, -1.2713e-05, -5.4604e-05, -4.9183e-05, -8.0534e-05,\n",
              "            -3.6502e-05, -5.0092e-05,  3.9095e-05, -3.4216e-05, -2.3584e-05,\n",
              "             8.9273e-06,  8.1293e-05,  7.1738e-05,  4.8163e-05,  7.1692e-05,\n",
              "            -6.5500e-05,  5.4957e-05,  7.7862e-05, -5.5924e-05,  6.7306e-05,\n",
              "            -8.5174e-05, -4.3879e-05,  6.6336e-05, -3.0509e-05, -6.1301e-05]]),\n",
              "   'exp_avg_sq': tensor([[1.9683e-05, 1.4686e-05, 1.7795e-05, 1.6769e-05, 4.1884e-06, 1.5307e-05,\n",
              "            1.9439e-05, 1.0678e-05, 1.0072e-05, 2.6042e-05, 1.7189e-05, 2.6378e-05,\n",
              "            1.9409e-05, 1.7699e-05, 1.8884e-05, 1.9259e-05, 2.2695e-05, 2.3553e-05,\n",
              "            2.8228e-05, 2.5439e-05, 2.0046e-05, 3.7367e-06, 1.4153e-05, 2.1397e-05,\n",
              "            2.5412e-05, 1.5222e-05, 1.5338e-05, 1.8092e-05, 1.6307e-06, 2.0928e-05,\n",
              "            6.3358e-06, 1.8092e-05, 1.5256e-05, 2.3720e-05, 1.8864e-05, 1.7245e-05,\n",
              "            1.6862e-05, 2.2659e-05, 6.4184e-06, 2.3649e-05, 1.1862e-05, 1.7431e-05,\n",
              "            1.8595e-05, 1.8130e-05, 3.3524e-05, 2.3749e-05, 6.6107e-06, 1.9514e-05,\n",
              "            2.2123e-05, 5.0920e-06, 2.2389e-05, 2.4231e-05, 7.0957e-06, 1.8579e-05,\n",
              "            2.0283e-05, 2.7356e-05, 1.8519e-05, 2.1416e-05, 3.5305e-06, 2.0069e-05,\n",
              "            1.2878e-06, 2.0003e-05, 2.5176e-05, 4.3003e-06, 1.8932e-05, 2.6147e-05,\n",
              "            2.6993e-05, 1.2921e-05, 2.3404e-05, 2.6842e-05, 2.4724e-05, 1.7562e-05,\n",
              "            1.8529e-05, 2.1557e-05, 2.4830e-05, 3.6348e-05, 1.8108e-05, 1.8371e-05,\n",
              "            1.4885e-05, 1.4633e-05, 1.2483e-05, 2.2804e-05, 1.8988e-05, 2.6437e-05,\n",
              "            1.6703e-05, 2.0220e-05, 2.0325e-05, 1.9984e-05, 1.8325e-05, 2.2655e-05,\n",
              "            1.5261e-05, 1.9622e-05, 2.4232e-05, 1.4298e-05, 2.0883e-05, 1.2750e-05,\n",
              "            2.2381e-05, 2.2442e-05, 2.3417e-05, 8.7243e-06],\n",
              "           [3.1889e-05, 2.1947e-05, 1.9493e-05, 3.2624e-05, 1.2079e-05, 3.2989e-05,\n",
              "            3.2814e-05, 2.8067e-05, 1.5274e-05, 6.4835e-05, 3.1218e-05, 5.4520e-05,\n",
              "            2.5767e-05, 3.3267e-05, 3.7305e-05, 2.0267e-05, 3.0697e-05, 4.6057e-05,\n",
              "            5.9574e-05, 5.7422e-05, 2.3899e-05, 1.0422e-05, 2.8228e-05, 2.5047e-05,\n",
              "            4.1976e-05, 3.3106e-05, 1.5516e-05, 1.7751e-05, 4.6208e-06, 4.5451e-05,\n",
              "            1.6105e-05, 2.9540e-05, 2.3968e-05, 4.4155e-05, 4.1675e-05, 3.4156e-05,\n",
              "            3.4574e-05, 2.8165e-05, 1.6100e-05, 3.1404e-05, 1.7506e-05, 2.0423e-05,\n",
              "            2.3517e-05, 3.9840e-05, 7.2358e-05, 3.0076e-05, 1.6149e-05, 4.0278e-05,\n",
              "            2.9719e-05, 1.3914e-05, 3.2345e-05, 2.9581e-05, 1.7043e-05, 3.4086e-05,\n",
              "            4.2992e-05, 6.1994e-05, 3.0805e-05, 4.9035e-05, 8.0339e-06, 2.3430e-05,\n",
              "            3.6896e-06, 4.5971e-05, 4.8754e-05, 1.0051e-05, 2.0047e-05, 4.2639e-05,\n",
              "            4.5518e-05, 3.2371e-05, 4.1238e-05, 4.1188e-05, 3.9478e-05, 1.4798e-05,\n",
              "            2.1395e-05, 3.2962e-05, 3.5216e-05, 6.9413e-05, 2.7360e-05, 4.1348e-05,\n",
              "            2.7364e-05, 3.6124e-05, 1.9616e-05, 4.3941e-05, 2.7185e-05, 5.1470e-05,\n",
              "            2.8852e-05, 4.1806e-05, 2.1702e-05, 2.4818e-05, 1.9785e-05, 3.0879e-05,\n",
              "            3.4831e-05, 2.3950e-05, 4.1321e-05, 3.1227e-05, 2.3475e-05, 3.2900e-05,\n",
              "            4.5944e-05, 2.8513e-05, 3.9503e-05, 1.9395e-05],\n",
              "           [1.5271e-05, 7.1341e-06, 1.2656e-05, 2.7974e-05, 9.6820e-06, 2.7434e-05,\n",
              "            3.2624e-05, 1.7162e-05, 1.2041e-05, 2.8951e-05, 7.7855e-06, 2.8017e-05,\n",
              "            1.0382e-05, 1.6993e-05, 2.3570e-05, 1.1829e-05, 1.2667e-05, 1.1293e-05,\n",
              "            3.5046e-05, 3.0824e-05, 1.2335e-05, 1.7142e-06, 1.4134e-05, 1.3110e-05,\n",
              "            1.7230e-05, 2.5616e-05, 6.8637e-06, 1.3167e-05, 7.7165e-07, 2.8241e-05,\n",
              "            1.5109e-05, 8.0279e-06, 3.1285e-05, 3.6788e-05, 2.8763e-05, 2.8585e-05,\n",
              "            1.7517e-05, 1.2839e-05, 1.9098e-05, 1.4879e-05, 6.1597e-06, 9.7486e-06,\n",
              "            9.6489e-06, 2.9343e-05, 3.9734e-05, 1.2553e-05, 1.2484e-05, 2.9770e-05,\n",
              "            1.4940e-05, 2.2711e-06, 1.2205e-05, 1.3560e-05, 1.5288e-05, 2.4623e-05,\n",
              "            2.9657e-05, 2.6301e-05, 9.1570e-06, 2.7610e-05, 8.9552e-06, 1.1117e-05,\n",
              "            6.2838e-07, 2.6223e-05, 3.6863e-05, 1.4718e-05, 1.0822e-05, 1.6911e-05,\n",
              "            1.7653e-05, 2.1358e-05, 3.1822e-05, 1.4891e-05, 1.5524e-05, 1.1590e-05,\n",
              "            1.0631e-05, 9.5657e-06, 1.4605e-05, 2.3056e-05, 1.1998e-05, 2.8044e-05,\n",
              "            2.9684e-05, 1.9427e-05, 1.5091e-05, 3.1794e-05, 9.1641e-06, 3.4618e-05,\n",
              "            1.2224e-05, 2.1587e-05, 1.3054e-05, 1.3294e-05, 1.0805e-05, 1.5406e-05,\n",
              "            2.4328e-05, 1.2120e-05, 1.7588e-05, 2.4372e-05, 1.2130e-05, 2.1512e-05,\n",
              "            3.4431e-05, 1.4118e-05, 3.3227e-05, 1.9792e-05]]),\n",
              "   'step': 1000}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZDXSaoq0sJP",
        "colab_type": "text"
      },
      "source": [
        "#More robust way to save parameters of a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS-9EIFz09Ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e16bd64-7b2e-4e0a-c63d-39503cc45688"
      },
      "source": [
        "cd \"/content/drive/My Drive/Deep_Learning_Projects/Wine_Dataset/\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Deep_Learning_Projects/Wine_Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6jcXXQQ0nRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), \"models/wine_classifier_state_dict\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d9kybpi1Gjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxZpIOZR1ZgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7d55720-168a-4aac-d1eb-733d0fa833e9"
      },
      "source": [
        "new_model.load_state_dict(torch.load('models/wine_classifier_state_dict'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utpJZG9d1ixK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "e874c430-673e-4368-fe46-2ff6c3889240"
      },
      "source": [
        "new_model.eval()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEhrx2_m1nr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_out = new_model(X_test)\n",
        "_, predict_y = torch.max(predict_out, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apni1OBB1rQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gx5tKRk1t7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "cd70a7ed-6c11-4abd-a7a0-b2a1031b6386"
      },
      "source": [
        "print(\"Accuracy score : \", accuracy_score(Y_test.data, predict_y.data))\n",
        "print(\"Precision score : \", precision_score(Y_test.data, predict_y.data, average='micro'))\n",
        "print(\"Recall score : \", recall_score(Y_test.data, predict_y.data, average='micro'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score :  0.9305555555555556\n",
            "Precision score :  0.9305555555555556\n",
            "Recall score :  0.9305555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZm6qHb81vfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}